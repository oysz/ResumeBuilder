/**
 * AI æœåŠ¡ - è°ƒç”¨æ™ºè°± AI API
 */

import CryptoJS from 'crypto-js';
import type {
  GLMChatRequest,
  GLMChatResponse,
  StreamChunk,
  ChatMessage,
} from '../types/ai.types';

// API ç«¯ç‚¹
const API_BASE_URL = 'https://open.bigmodel.cn/api/paas/v4/chat/completions';

// æœ¬åœ°å­˜å‚¨ key
const STORAGE_KEY = 'ai_api_key_encrypted';

// åŠ å¯†å¯†é’¥ï¼ˆä½¿ç”¨å›ºå®šç›å€¼ï¼‰
const SECRET_KEY = 'resume-builder-ai-secret-2024';

/**
 * åŠ å¯†å¹¶ä¿å­˜ API Key
 */
export function saveApiKey(apiKey: string): void {
  if (!apiKey || apiKey.trim() === '') {
    localStorage.removeItem(STORAGE_KEY);
    return;
  }

  const encrypted = CryptoJS.AES.encrypt(apiKey, SECRET_KEY).toString();
  localStorage.setItem(STORAGE_KEY, encrypted);
}

/**
 * è§£å¯†å¹¶è·å– API Key
 */
export function getApiKey(): string | null {
  const encrypted = localStorage.getItem(STORAGE_KEY);
  if (!encrypted) return null;

  try {
    const decrypted = CryptoJS.AES.decrypt(encrypted, SECRET_KEY);
    return decrypted.toString(CryptoJS.enc.Utf8);
  } catch (error) {
    console.error('Failed to decrypt API key:', error);
    return null;
  }
}

/**
 * æ£€æŸ¥æ˜¯å¦å·²é…ç½® API Key
 */
export function hasApiKey(): boolean {
  return getApiKey() !== null;
}

/**
 * æ„å»ºç³»ç»Ÿæç¤ºè¯
 */
function buildSystemPrompt(context?: string): string {
  const basePrompt = `ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„ç®€å†é¡¾é—®å’Œå†™ä½œåŠ©æ‰‹ã€‚ä½ çš„ä»»åŠ¡æ˜¯å¸®åŠ©ç”¨æˆ·ä¼˜åŒ–ç®€å†å†…å®¹ï¼Œä½¿å…¶æ›´åŠ ä¸“ä¸šã€æœ‰å¸å¼•åŠ›ã€‚

ä½ çš„èƒ½åŠ›åŒ…æ‹¬ï¼š
1. ä¼˜åŒ–å·¥ä½œç»å†æè¿°ï¼Œä½¿å…¶æ›´åŠ ç®€æ´ã€æœ‰åŠ›
2. ç”Ÿæˆä¸“ä¸šçš„è‡ªæˆ‘ä»‹ç»å’Œæ±‚èŒä¿¡
3. æ ¹æ®èŒä½æè¿°ï¼ˆJDï¼‰è°ƒæ•´ç®€å†å†…å®¹
4. æ”¹è¿›ç®€å†çš„è¯­è¨€è¡¨è¾¾å’Œä¸“ä¸šæ€§

è¯·éµå¾ªä»¥ä¸‹åŸåˆ™ï¼š
- ä½¿ç”¨ä¸“ä¸šçš„èŒåœºè¯­è¨€
- é‡åŒ–æˆæœï¼ˆä½¿ç”¨æ•°å­—ã€ç™¾åˆ†æ¯”ç­‰ï¼‰
- ä½¿ç”¨åŠ¨ä½œåŠ¨è¯å¼€å¤´
- ä¿æŒç®€æ´ï¼Œå»é™¤å†—ä½™
- çªå‡ºæ ¸å¿ƒæŠ€èƒ½å’Œæˆå°±

å›å¤æ—¶è¯·ä½¿ç”¨ Markdown æ ¼å¼ï¼Œä¿æŒç®€æ´ä¸“ä¸šã€‚`;

  if (context) {
    return `${basePrompt}\n\nå½“å‰ç®€å†ä¸Šä¸‹æ–‡ï¼š\n${context}`;
  }

  return basePrompt;
}

/**
 * è°ƒç”¨æ™ºè°± AI APIï¼ˆéæµå¼ï¼‰
 */
export async function callGLMAPI(
  messages: ChatMessage[],
  model: string = 'glm-4',
  temperature: number = 0.7,
  maxTokens: number = 2000
): Promise<string> {
  const apiKey = getApiKey();

  if (!apiKey) {
    throw new Error('è¯·å…ˆé…ç½® API Key');
  }

  // æ„å»ºè¯·æ±‚
  const request: GLMChatRequest = {
    model: model as any,
    messages: messages.map(msg => ({
      role: msg.role,
      content: msg.content,
    })),
    temperature,
    max_tokens: maxTokens,
  };

  try {
    const response = await fetch(API_BASE_URL, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'Authorization': `Bearer ${apiKey}`,
      },
      body: JSON.stringify(request),
    });

    if (!response.ok) {
      const error = await response.text();
      throw new Error(`API è¯·æ±‚å¤±è´¥: ${response.status} - ${error}`);
    }

    const data: GLMChatResponse = await response.json();
    return data.choices[0]?.message?.content || '';
  } catch (error) {
    console.error('GLM API Error:', error);
    throw error;
  }
}

/**
 * è°ƒç”¨æ™ºè°± AI APIï¼ˆæµå¼ï¼‰
 */
export async function callGLMAPIStream(
  messages: ChatMessage[],
  onChunk: (content: string) => void,
  onComplete: () => void,
  onError: (error: Error) => void,
  model: string = 'glm-4',
  temperature: number = 0.7,
  maxTokens: number = 2000
): Promise<void> {
  const apiKey = getApiKey();

  if (!apiKey) {
    onError(new Error('è¯·å…ˆé…ç½® API Key'));
    return;
  }

  // æ„å»ºè¯·æ±‚
  const request: GLMChatRequest = {
    model: model as any,
    messages: messages.map(msg => ({
      role: msg.role,
      content: msg.content,
    })),
    stream: true,
    temperature,
    max_tokens: maxTokens,
  };

  try {
    const response = await fetch(API_BASE_URL, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'Authorization': `Bearer ${apiKey}`,
      },
      body: JSON.stringify(request),
    });

    if (!response.ok) {
      const error = await response.text();
      throw new Error(`API è¯·æ±‚å¤±è´¥: ${response.status} - ${error}`);
    }

    const reader = response.body?.getReader();
    if (!reader) {
      throw new Error('æ— æ³•è¯»å–å“åº”æµ');
    }

    const decoder = new TextDecoder('utf-8');
    let buffer = '';

    while (true) {
      const { done, value } = await reader.read();

      if (done) {
        onComplete();
        break;
      }

      buffer += decoder.decode(value, { stream: true });
      const lines = buffer.split('\n');
      buffer = lines.pop() || '';

      for (const line of lines) {
        if (line.startsWith('data: ')) {
          const data = line.slice(6);

          if (data === '[DONE]') {
            onComplete();
            return;
          }

          try {
            const chunk: StreamChunk = JSON.parse(data);
            const content = chunk.choices[0]?.delta?.content;

            if (content) {
              onChunk(content);
            }

            if (chunk.choices[0]?.finish_reason) {
              onComplete();
              return;
            }
          } catch (e) {
            // å¿½ç•¥è§£æé”™è¯¯
          }
        }
      }
    }
  } catch (error) {
    console.error('GLM API Stream Error:', error);
    onError(error as Error);
  }
}

/**
 * å¿«æ·æ“ä½œ - ä¼˜åŒ–æè¿°
 */
export function optimizeDescription(text: string): Promise<string> {
  const messages: ChatMessage[] = [
    {
      id: '1',
      role: 'system',
      content: buildSystemPrompt(),
      timestamp: Date.now(),
    },
    {
      id: '2',
      role: 'user',
      content: `è¯·ä¼˜åŒ–ä»¥ä¸‹ç®€å†å†…å®¹ï¼Œä½¿å…¶æ›´åŠ ä¸“ä¸šã€ç®€æ´ã€æœ‰åŠ›ï¼š\n\n${text}`,
      timestamp: Date.now(),
    },
  ];

  return callGLMAPI(messages);
}

/**
 * å¿«æ·æ“ä½œ - ç”Ÿæˆè‡ªæˆ‘ä»‹ç»
 */
export function generateIntroduction(resumeData: any): Promise<string> {
  const messages: ChatMessage[] = [
    {
      id: '1',
      role: 'system',
      content: buildSystemPrompt(JSON.stringify(resumeData)),
      timestamp: Date.now(),
    },
    {
      id: '2',
      role: 'user',
      content: 'è¯·ä¸ºè¿™ä»½ç®€å†ç”Ÿæˆä¸€æ®µç®€æ´ã€ä¸“ä¸šçš„è‡ªæˆ‘ä»‹ç»ï¼ˆ100-150å­—ï¼‰',
      timestamp: Date.now(),
    },
  ];

  return callGLMAPI(messages);
}

/**
 * å¿«æ·æ“ä½œ - æ¶¦è‰²å·¥ä½œç»å†
 */
export function polishExperience(experience: string): Promise<string> {
  const messages: ChatMessage[] = [
    {
      id: '1',
      role: 'system',
      content: buildSystemPrompt(),
      timestamp: Date.now(),
    },
    {
      id: '2',
      role: 'user',
      content: `è¯·æ¶¦è‰²ä»¥ä¸‹å·¥ä½œç»å†æè¿°ï¼Œä½¿å…¶æ›´åŠ ä¸“ä¸šå’Œå¸å¼•äººï¼š\n\n${experience}\n\nè¯·ä¿æŒåŸæœ‰äº‹å®ï¼Œåªæ˜¯æ”¹è¿›è¡¨è¾¾æ–¹å¼ã€‚`,
      timestamp: Date.now(),
    },
  ];

  return callGLMAPI(messages);
}

/**
 * å¿«æ·æ“ä½œ - åŒ¹é…èŒä½æè¿°
 */
export function matchJobDescription(resumeData: any, jd: string): Promise<string> {
  const messages: ChatMessage[] = [
    {
      id: '1',
      role: 'system',
      content: buildSystemPrompt(),
      timestamp: Date.now(),
    },
    {
      id: '2',
      role: 'user',
      content: `è¯·åˆ†æä»¥ä¸‹èŒä½æè¿°ï¼Œå¹¶ç»™å‡ºç®€å†ä¼˜åŒ–å»ºè®®ï¼š\n\nèŒä½æè¿°ï¼š\n${jd}\n\nè¯·å‘Šè¯‰æˆ‘ï¼š1. ç®€å†ä¸­éœ€è¦å¼ºè°ƒå“ªäº›æŠ€èƒ½å’Œç»éªŒï¼Ÿ2. å“ªäº›å…³é”®è¯åº”è¯¥åŒ…å«åœ¨ç®€å†ä¸­ï¼Ÿ3. æœ‰å“ªäº›éœ€è¦è¡¥å……çš„å†…å®¹ï¼Ÿ`,
      timestamp: Date.now(),
    },
  ];

  return callGLMAPI(messages);
}

// ============ AI æ¶¦è‰²åŠŸèƒ½ ============

import type { PolishMode, PolishRequest } from '@/types/ai.types';

/**
 * æ„å»ºæ¶¦è‰²æç¤ºè¯
 */
function buildPolishPrompt(mode: PolishMode, content: string, context?: string): string {
  const prompts = {
    polish: `è¯·æ¶¦è‰²ä»¥ä¸‹å†…å®¹ï¼Œä½¿å…¶æ›´åŠ ä¸“ä¸šã€æµç•…ã€æœ‰å¸å¼•åŠ›ã€‚

è¦æ±‚ï¼š
1. æ”¹è¿›è¯­è¨€è¡¨è¾¾ï¼Œä½¿ç”¨æ›´ä¸“ä¸šçš„è¯æ±‡
2. ä¼˜åŒ–å¥å­ç»“æ„ï¼Œä½¿è¡¨è¾¾æ›´æµç•…
3. ä¿æŒåŸæ„ä¸å˜ï¼Œä¸è¦æ·»åŠ è™šæ„ä¿¡æ¯
4. é€‚å½“æ·»åŠ åŠ¨ä½œåŠ¨è¯å’Œé‡åŒ–è¡¨è¾¾

åŸå†…å®¹ï¼š
${content}

è¯·åªè¿”å›æ¶¦è‰²åçš„å†…å®¹ï¼Œä¸è¦åŒ…å«ä»»ä½•è§£é‡Šã€‚`,

    expand: `è¯·æ‰©å±•ä»¥ä¸‹å†…å®¹ï¼Œä½¿å…¶æ›´åŠ ä¸°å¯Œã€è¯¦ç»†ã€‚

è¦æ±‚ï¼š
1. å¢åŠ å…·ä½“ç»†èŠ‚å’Œå®ä¾‹
2. è¡¥å……ç›¸å…³çš„æŠ€èƒ½å’Œç»éªŒ
3. é‡åŒ–æˆæœï¼ˆä½¿ç”¨æ•°å­—ã€ç™¾åˆ†æ¯”ç­‰ï¼‰
4. ä½¿å†…å®¹æ›´åŠ ç«‹ä½“å’Œæœ‰è¯´æœåŠ›
5. æ§åˆ¶åœ¨åŸå†…å®¹çš„2-3å€é•¿åº¦

åŸå†…å®¹ï¼š
${content}

è¯·åªè¿”å›æ‰©å±•åçš„å†…å®¹ï¼Œä¸è¦åŒ…å«ä»»ä½•è§£é‡Šã€‚`,

    simplify: `è¯·ç²¾ç®€ä»¥ä¸‹å†…å®¹ï¼Œæç‚¼æ ¸å¿ƒè¦ç‚¹ã€‚

è¦æ±‚ï¼š
1. å»é™¤å†—ä½™å’Œæ— å…³ä¿¡æ¯
2. ä¿ç•™æœ€é‡è¦çš„å…³é”®ä¿¡æ¯
3. ä½¿ç”¨ç®€æ´æœ‰åŠ›çš„è¡¨è¾¾
4. å¦‚æœæ˜¯å·¥ä½œç»å†ï¼Œè½¬æ¢ä¸ºè¦ç‚¹æ ¼å¼ï¼ˆæ¯ä¸ªè¦ç‚¹ä¸€è¡Œï¼‰
5. æ§åˆ¶åœ¨åŸå†…å®¹çš„50%-70%é•¿åº¦

åŸå†…å®¹ï¼š
${content}

è¯·åªè¿”å›ç²¾ç®€åçš„å†…å®¹ï¼Œä¸è¦åŒ…å«ä»»ä½•è§£é‡Šã€‚`,

    format: `è¯·å°†ä»¥ä¸‹å†…å®¹æ ¼å¼åŒ–ä¸ºä¸“ä¸šçš„ç®€å†è¦ç‚¹ã€‚

è¦æ±‚ï¼š
1. ä½¿ç”¨è¦ç‚¹æ ¼å¼ï¼ˆæ¯è¡Œä¸€ä¸ªè¦ç‚¹ï¼Œä»¥ â€¢ æˆ–æ•°å­—å¼€å¤´ï¼‰
2. æ¯ä¸ªè¦ç‚¹ä»¥åŠ¨ä½œåŠ¨è¯å¼€å¤´ï¼ˆå¦‚"è´Ÿè´£"ã€"å¼€å‘"ã€"å®ç°"ç­‰ï¼‰
3. é‡åŒ–æˆæœï¼ˆåŠ å…¥æ•°å­—ã€ç™¾åˆ†æ¯”ç­‰ï¼‰
4. çªå‡ºæ ¸å¿ƒæŠ€èƒ½å’Œæˆå°±
5. ä½¿å†…å®¹æ›´æ˜“è¯»ã€æ›´æœ‰å†²å‡»åŠ›

åŸå†…å®¹ï¼š
${content}

è¯·åªè¿”å›æ ¼å¼åŒ–åçš„å†…å®¹ï¼Œä¸è¦åŒ…å«ä»»ä½•è§£é‡Šã€‚`
  };

  let prompt = prompts[mode];

  if (context) {
    prompt = `è¿™æ˜¯ç®€å†ä¸­çš„ã€${context}ã€‘éƒ¨åˆ†ã€‚\n\n${prompt}`;
  }

  return prompt;
}

/**
 * AI æ¶¦è‰²ï¼ˆéæµå¼ï¼‰
 */
export function polishContent(
  content: string,
  mode: PolishMode,
  context?: string
): Promise<string> {
  const messages: ChatMessage[] = [
    {
      id: '1',
      role: 'system',
      content: buildSystemPrompt(),
      timestamp: Date.now(),
    },
    {
      id: '2',
      role: 'user',
      content: buildPolishPrompt(mode, content, context),
      timestamp: Date.now(),
    },
  ];

  return callGLMAPI(messages);
}

/**
 * AI æ¶¦è‰²ï¼ˆæµå¼ï¼‰
 */
export function polishContentStream(
  content: string,
  mode: PolishMode,
  onChunk: (text: string) => void,
  onComplete: (finalText: string) => void,
  onError: (error: Error) => void,
  context?: string
): void {
  const messages: ChatMessage[] = [
    {
      id: '1',
      role: 'system',
      content: buildSystemPrompt(),
      timestamp: Date.now(),
    },
    {
      id: '2',
      role: 'user',
      content: buildPolishPrompt(mode, content, context),
      timestamp: Date.now(),
    },
  ];

  let fullContent = '';

  callGLMAPIStream(
    messages,
    (chunk) => {
      fullContent += chunk;
      onChunk(chunk);
    },
    () => {
      onComplete(fullContent);
    },
    onError
  );
}

/**
 * è·å–æ¶¦è‰²æ¨¡å¼é…ç½®
 */
export function getPolishModeConfig(mode: PolishMode) {
  const configs: Record<PolishMode, { label: string; description: string; icon: string; color: string }> = {
    polish: {
      label: 'åŸºç¡€æ¶¦è‰²',
      description: 'æ”¹è¿›è¯­è¨€è¡¨è¾¾ï¼Œä½¿å…¶æ›´ä¸“ä¸šæµç•…',
      icon: 'âœ¨',
      color: 'purple'
    },
    expand: {
      label: 'å†…å®¹æ‰©å±•',
      description: 'å¢åŠ æ›´å¤šç»†èŠ‚ï¼Œä½¿å†…å®¹æ›´ä¸°å¯Œ',
      icon: 'ğŸ“',
      color: 'blue'
    },
    simplify: {
      label: 'ç²¾ç®€å†…å®¹',
      description: 'æç‚¼æ ¸å¿ƒè¦ç‚¹ï¼Œå»é™¤å†—ä½™',
      icon: 'ğŸ¯',
      color: 'green'
    },
    format: {
      label: 'æ ¼å¼ä¼˜åŒ–',
      description: 'è½¬æ¢ä¸ºä¸“ä¸šçš„ç®€å†è¦ç‚¹æ ¼å¼',
      icon: 'ğŸ“‹',
      color: 'orange'
    }
  };

  return configs[mode];
}
